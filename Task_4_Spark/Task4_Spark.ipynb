{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc228d14-59d3-450c-9517-501b7c0ea728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Movies Analysis\") \\\n",
    "    .config(\"spark.jars\", \"C:\\\\Users\\\\Admin\\\\Downloads\\\\postgresql-42.7.8.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "url = \"jdbc:postgresql://localhost:5432/pagila\"\n",
    "properties = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"root\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "films_df = spark.read.jdbc(url=url, table=\"film\", properties=properties)\n",
    "actors_df = spark.read.jdbc(url=url, table=\"actor\", properties=properties)\n",
    "rental_df = spark.read.jdbc(url=url, table=\"rental\", properties=properties)\n",
    "category_df = spark.read.jdbc(url=url, table=\"category\", properties=properties)\n",
    "inventory_df = spark.read.jdbc(url=url, table=\"inventory\", properties=properties)\n",
    "film_category_df = spark.read.jdbc(url=url, table=\"film_category\", properties=properties)\n",
    "customer_df = spark.read.jdbc(url=url, table=\"customer\", properties=properties)\n",
    "address_df = spark.read.jdbc(url=url, table=\"address\", properties=properties)\n",
    "city_df = spark.read.jdbc(url=url, table=\"city\", properties=properties)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5659344f-3378-4aa1-8fb0-36acf70c3539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|       name|film_count|\n",
      "+-----------+----------+\n",
      "|      Drama|       152|\n",
      "|      Music|       152|\n",
      "|     Travel|       151|\n",
      "|    Foreign|       150|\n",
      "|      Games|       150|\n",
      "|   Children|       150|\n",
      "|     Action|       149|\n",
      "|     Sci-Fi|       149|\n",
      "|  Animation|       148|\n",
      "|     Family|       147|\n",
      "|   Classics|       147|\n",
      "|        New|       147|\n",
      "|     Sports|       145|\n",
      "|Documentary|       145|\n",
      "|     Comedy|       143|\n",
      "|     Horror|       142|\n",
      "+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "film_category_df = spark.read.jdbc(url=url, table=\"film_category\", properties=properties)\n",
    "\n",
    "category_count = category_df \\\n",
    "    .join(film_category_df, \"category_id\") \\\n",
    "    .join(films_df, \"film_id\") \\\n",
    "    .groupBy(\"name\") \\\n",
    "    .agg(F.count(\"film_id\").alias(\"film_count\")) \\\n",
    "    .orderBy(F.desc(\"film_count\"))\n",
    "\n",
    "category_count.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbad6e65-9afd-4aa4-8947-548b0af328b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+------------+\n",
      "|actor_id|first_name|  last_name|rental_count|\n",
      "+--------+----------+-----------+------------+\n",
      "|     107|      GINA|  DEGENERES|         753|\n",
      "|     181|   MATTHEW|     CARREY|         678|\n",
      "|     198|      MARY|     KEITEL|         674|\n",
      "|     144|    ANGELA|WITHERSPOON|         654|\n",
      "|     102|    WALTER|       TORN|         640|\n",
      "|      60|     HENRY|      BERRY|         612|\n",
      "|     150|     JAYNE|      NOLTE|         611|\n",
      "|      37|       VAL|     BOLGER|         605|\n",
      "|      23|    SANDRA|     KILMER|         604|\n",
      "|      90|      SEAN|    GUINESS|         599|\n",
      "+--------+----------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "film_actor_df = spark.read.jdbc(url=url, table=\"film_actor\", properties=properties)\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "actor_rental_count = actors_df \\\n",
    "    .join(film_actor_df, \"actor_id\") \\\n",
    "    .join(films_df, \"film_id\") \\\n",
    "    .join(inventory_df, \"film_id\") \\\n",
    "    .join(rental_df, \"inventory_id\") \\\n",
    "    .groupBy(\"actor_id\", \"first_name\", \"last_name\") \\\n",
    "    .agg(F.count(\"rental_id\").alias(\"rental_count\")) \\\n",
    "    .orderBy(F.desc(\"rental_count\")) \\\n",
    "    .limit(10)\n",
    "\n",
    "actor_rental_count.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb8d9362-245d-43de-9bdd-e63ec32d2856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "|   name|total_revenue|\n",
      "+-------+-------------+\n",
      "|Foreign|     10507.67|\n",
      "+-------+-------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payment_df = spark.read.jdbc(url=url, table=\"payment\", properties=properties)\n",
    "\n",
    "category_revenue = category_df \\\n",
    "    .join(film_category_df, \"category_id\") \\\n",
    "    .join(films_df, \"film_id\") \\\n",
    "    .join(inventory_df, \"film_id\") \\\n",
    "    .join(rental_df, \"inventory_id\") \\\n",
    "    .join(payment_df, \"rental_id\") \\\n",
    "    .groupBy(\"name\") \\\n",
    "    .agg(F.sum(\"amount\").alias(\"total_revenue\")) \\\n",
    "    .orderBy(F.desc(\"total_revenue\"))\n",
    "\n",
    "category_revenue.show(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01182707-3d64-48b6-b529-4b345f911c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               title|\n",
      "+--------------------+\n",
      "|      CHOCOLATE DUCK|\n",
      "|       BUTCH PANTHER|\n",
      "|        VOLUME HOUSE|\n",
      "|      ORDER BETRAYED|\n",
      "|        TADPOLE PARK|\n",
      "|    KILL BROTHERHOOD|\n",
      "|FRANKENSTEIN STRA...|\n",
      "|    CROSSING DIVORCE|\n",
      "|    SUICIDES SILENCE|\n",
      "|       CATCH AMISTAD|\n",
      "|     PERDITION FARGO|\n",
      "|       FLOATS GARDEN|\n",
      "|           GUMP DATE|\n",
      "|        WALLS ARTIST|\n",
      "|  GLADIATOR WESTWARD|\n",
      "|         HOCUS FRIDA|\n",
      "|ARSENIC INDEPENDENCE|\n",
      "|         MUPPET MILE|\n",
      "|   FIREHOUSE VIETNAM|\n",
      "|       ROOF CHAMPION|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "films_not_in_inventory = films_df.join(inventory_df, \"film_id\", \"left_anti\")\n",
    "\n",
    "films_not_in_inventory.select(\"title\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5071a43e-18ca-4448-9897-a13c8ab8d244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+\n",
      "|first_name|last_name|film_count|\n",
      "+----------+---------+----------+\n",
      "|    SIDNEY|    CROWE|         9|\n",
      "|      EWAN|  GOODING|         9|\n",
      "|   RICHARD|     PENN|         9|\n",
      "|   SPENCER|     PECK|         8|\n",
      "|       KIM|    ALLEN|         8|\n",
      "|      MARY|    TANDY|         8|\n",
      "|      ALEC|    WAYNE|         8|\n",
      "|       DAN|   HARRIS|         8|\n",
      "|   RUSSELL|   TEMPLE|         8|\n",
      "|   MATTHEW|   CARREY|         8|\n",
      "|      JANE|  JACKMAN|         8|\n",
      "|      JADA|    RYDER|         8|\n",
      "|     JAMES|     PITT|         7|\n",
      "|    WARREN|    NOLTE|         7|\n",
      "|  JULIANNE|    DENCH|         7|\n",
      "|    AUDREY|  OLIVIER|         7|\n",
      "|      GENE|   WILLIS|         7|\n",
      "|    ANGELA|   HUDSON|         7|\n",
      "|     DARYL| WAHLBERG|         7|\n",
      "|   KENNETH|     TORN|         7|\n",
      "+----------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "children_actors = actors_df \\\n",
    "    .join(film_actor_df, \"actor_id\") \\\n",
    "    .join(films_df, \"film_id\") \\\n",
    "    .join(film_category_df, \"film_id\") \\\n",
    "    .join(category_df, \"category_id\") \\\n",
    "    .filter(F.col(\"name\") == \"Children\") \\\n",
    "    .groupBy(\"actor_id\", \"first_name\", \"last_name\") \\\n",
    "    .agg(F.count(\"film_id\").alias(\"film_count\"))\n",
    "\n",
    "window = Window.orderBy(F.desc(\"film_count\"))\n",
    "top3_children_actors = children_actors.withColumn(\"rank\", F.dense_rank().over(window)) \\\n",
    "    .filter(F.col(\"rank\") <= 3)\n",
    "\n",
    "top3_children_actors.select(\"first_name\", \"last_name\", \"film_count\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d887c73-0990-4e00-bd02-6a8c7614749c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+--------------+\n",
      "|              city|active_count|inactive_count|\n",
      "+------------------+------------+--------------+\n",
      "|          Uluberia|           0|             1|\n",
      "|         Najafabad|           0|             1|\n",
      "|         Pingxiang|           0|             1|\n",
      "|          Xiangfan|           0|             1|\n",
      "|        Kumbakonam|           0|             1|\n",
      "|       Szkesfehrvr|           0|             1|\n",
      "|  Charlotte Amalie|           0|             1|\n",
      "|            Kamyin|           0|             1|\n",
      "|            Daxian|           0|             1|\n",
      "|     Coatzacoalcos|           0|             1|\n",
      "|           Wroclaw|           0|             1|\n",
      "|            Ktahya|           0|             1|\n",
      "|            Amroha|           0|             1|\n",
      "|   Southend-on-Sea|           0|             1|\n",
      "|           Bat Yam|           0|             1|\n",
      "|          Fengshan|           1|             0|\n",
      "|A Corua (La Corua)|           1|             0|\n",
      "|           El Alto|           1|             0|\n",
      "|              Linz|           1|             0|\n",
      "|          Myingyan|           1|             0|\n",
      "+------------------+------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "city_client_status = customer_df \\\n",
    "    .join(address_df, \"address_id\") \\\n",
    "    .join(city_df, \"city_id\") \\\n",
    "    .groupBy(\"city\") \\\n",
    "    .agg(\n",
    "        F.sum(F.col(\"active\")).alias(\"active_count\"),\n",
    "        F.sum(F.when(F.col(\"active\") == 0, 1).otherwise(0)).alias(\"inactive_count\")\n",
    "    ) \\\n",
    "    .orderBy(F.desc(\"inactive_count\"))\n",
    "\n",
    "city_client_status.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "576d70c2-dbca-4f66-b14c-707e3e6888d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------------------+\n",
      "| city_group|    name|total_rental_hours|\n",
      "+-----------+--------+------------------+\n",
      "|   A_cities|Children|               955|\n",
      "|dash_cities|  Sci-Fi|               576|\n",
      "+-----------+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "city_rental = rental_df \\\n",
    "    .join(inventory_df, \"inventory_id\") \\\n",
    "    .join(films_df, \"film_id\") \\\n",
    "    .join(film_category_df, \"film_id\") \\\n",
    "    .join(category_df, \"category_id\") \\\n",
    "    .join(customer_df, \"customer_id\") \\\n",
    "    .join(address_df, \"address_id\") \\\n",
    "    .join(city_df, \"city_id\") \\\n",
    "    .withColumn(\"rental_hours\", F.col(\"rental_duration\")) \\\n",
    "    .withColumn(\n",
    "        \"city_group\",\n",
    "        F.when(F.col(\"city\").startswith(\"A\"), \"A_cities\")\n",
    "         .when(F.col(\"city\").contains(\"-\"), \"dash_cities\")\n",
    "    )\n",
    "\n",
    "window_spec = Window.partitionBy(\"city_group\")\n",
    "\n",
    "city_category_hours = city_rental \\\n",
    "    .filter(F.col(\"city_group\").isNotNull()) \\\n",
    "    .groupBy(\"city_group\", \"name\") \\\n",
    "    .agg(F.sum(\"rental_hours\").alias(\"total_rental_hours\")) \\\n",
    "    .withColumn(\"max_hours\", F.max(\"total_rental_hours\").over(window_spec)) \\\n",
    "    .filter(F.col(\"total_rental_hours\") == F.col(\"max_hours\")) \\\n",
    "    .select(\"city_group\", \"name\", \"total_rental_hours\")\n",
    "\n",
    "city_category_hours.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feab5ed3-8ea2-4031-99b4-df9d0e893937",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
